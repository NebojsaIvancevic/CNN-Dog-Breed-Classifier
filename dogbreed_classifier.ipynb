{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of dogbreed-classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dD-YMmDcQsQfApQXmLSnHovWoxfY-v10",
      "authorship_tag": "ABX9TyMHIUSTAyRf8J4T5SqnQu5g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NebojsaIvancevic/CNN-Dog-Breed-Classifier/blob/main/dogbreed_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWL-fpxwjTVc"
      },
      "source": [
        "# Resources\n",
        "\n",
        "\n",
        "> [Deep learning with Python, TensorFlow and Keras](https://pythonprogramming.net/)\n",
        "\n",
        "\n",
        "> [Dog breed classifier transfer learning](https://towardsdatascience.com/dog-breed-classification-hands-on-approach-b5e4f88c333e)\n",
        "\n",
        "> [Best pre trained models](https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/)\n",
        "\n",
        "> [Basics of machine learning image techniques](https://iq.opengenus.org/basics-of-machine-learning-image-classification-techniques/)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPI7oqwp1qd7"
      },
      "source": [
        "#Create a dog breed classifier using convolutional neural networks and a pretrained model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flOokwAL1-lW"
      },
      "source": [
        "We are using the stanford dogs dataset from kaggle\n",
        "We are using colab provided gpus so we need to install required libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLQ06xLM2Z-1"
      },
      "source": [
        "import tensorflow as tf\n",
        "# tf.__version__\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pickle\n",
        "import cv2\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import load_img\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oTxRE3h2j3c"
      },
      "source": [
        "Also we are fetching data directly from the google drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCT3P8mzDPBg"
      },
      "source": [
        "Defined a function for building our model using mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp7C6CVYCc2r"
      },
      "source": [
        "def build_model(size, num_classes):\n",
        "  inputs = Input((size,size,3))\n",
        "  backbone = MobileNetV2(input_tensor = inputs, include_top=False, weights = \"imagenet\")\n",
        "  backbone.trainable = True\n",
        "  x = backbone.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = Dense(1024, activation=\"relu\")(x)\n",
        "  x = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "  model = tf.keras.Model(inputs, x)\n",
        "  return model\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80B7Eo5nDZi4"
      },
      "source": [
        "def read_image(path, size):\n",
        "  image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "  image = cv2.resize(image, (size,size))\n",
        "  image = image / 255.0\n",
        "  image = image.astype(np.float32)\n",
        "  return image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_SKP7JoDtbQ"
      },
      "source": [
        "def parse_data(x,y):\n",
        "  x = x.decode()\n",
        "\n",
        "  num_class = 120\n",
        "  size = 224\n",
        "\n",
        "  image = read_image(x,size)\n",
        "  label = [0] * num_class\n",
        "  label[y] = 1\n",
        "  label = np.array(label)\n",
        "  label = label.astype(np.int32)\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeVcSfh0ERPW"
      },
      "source": [
        "def tf_parse(x,y):\n",
        "  x, y = tf.numpy_function(parse_data, [x, y], [tf.float32, tf.int32])\n",
        "  x.set_shape((224, 224, 3))\n",
        "  y.set_shape((120))\n",
        "  return x, y\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39mHGRsSEnCm"
      },
      "source": [
        "def tf_dataset(x,y, batch=8):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "  dataset = dataset.map(tf_parse)\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.repeat()\n",
        "  return dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHloLb6iCH63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "2d21aec9-ce67-4fbe-bc8d-dc10bb475246"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  train_path = \"/content/drive/MyDrive/Datasets/dataset#6dogbreedclassification/train\"\n",
        "  test_path = \"/content/drive/MyDrive/Datasets/dataset#6dogbreedclassification/test\"\n",
        "  labels_path = \"/content/drive/MyDrive/Datasets/dataset#6dogbreedclassification/labels.csv\"\n",
        "\n",
        "  labels_df = pd.read_csv(labels_path)\n",
        "  labels.head()\n",
        "  breed = labels_df[\"breed\"].unique()\n",
        "  print(\"Number of breeds: \", len(breed))\n",
        "\n",
        "  breed2id = {name: i for i, name in enumerate(breed)}\n",
        "\n",
        "  ids = glbo(train_path)\n",
        "  labels = []\n",
        "\n",
        "  for image_id in ids:\n",
        "    image_id = image_id.split(\"\\\\\")[-1].split(\".\")[0]\n",
        "    breed_name = list(labels_df[labels_df.id == image_id][\"breed\"])(0)\n",
        "    breed_idx = breed2id[breed_name]\n",
        "    labels.append(breed_idx)\n",
        "  \n",
        "  ids = ids[:1000]\n",
        "  labels = labels[:1000]\n",
        "\n",
        "\n",
        "  ##Splitting data set\n",
        "  train_x, valid_x = train_test_split(ids, test_size=0.2, random_state=42) ##test size 20%\n",
        "  train_y, valid_y = train_test_split(labels, test_size = 0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "  ##hyper parameters\n",
        "  size = 224\n",
        "  num_classes = 120\n",
        "  lr = 1e-4 #0.00001\n",
        "  batch = 32\n",
        "  epochs = 20\n",
        "\n",
        "  ## Building the model\n",
        "\n",
        "  model = build_model(size, num_classes)\n",
        "  opt = tf.keras.optimizers.Adam(lr=lr)\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"acc\"])\n",
        "\n",
        "\n",
        "  ## Dataset\n",
        "\n",
        "  train_dataset = tf_dataset(train_x, train_y, batch = batch)\n",
        "  valid_dataset = tf_dataset(valid_x, valid_y, batch = batch)\n",
        "\n",
        "  ## Training\n",
        "\n",
        "  callbacks = [\n",
        "               ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True),\n",
        "               ReduceLROnPlateau(factor = 0.2, patience = 5, min_lr = 1e-6)\n",
        "  ]\n",
        "\n",
        "  train_steps = (len(train_x)//batch) + 1\n",
        "  valid_steps = (len(valid_x)//batch) + 1\n",
        "  model.fit(train_dataset,\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_steps=valid_steps,\n",
        "            validation_data=valid_dataset,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1912c1c217cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mlabels_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Datasets/dataset#6dogbreedclassification/labels.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mlabels_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mbreed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"breed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Datasets/dataset#6dogbreedclassification/labels.csv'"
          ]
        }
      ]
    }
  ]
}